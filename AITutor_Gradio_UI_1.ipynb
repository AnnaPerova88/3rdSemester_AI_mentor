{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JpCOVzho2D_"
      },
      "outputs": [],
      "source": [
        "!pip install -q gradio requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# üîë –í–°–¢–ê–í–¨ –°–Æ–î–ê –°–í–û–ô –ö–õ–Æ–ß\n",
        "os.environ[\"PERPLEXITY_API_KEY\"] = \"ppplx-dddXFbFD7qguGd9T8LVnrauz98765mYNCBHq091vZaZ33xtwtfyODOD\""
      ],
      "metadata": {
        "id": "7QT-h3pMo7hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import requests\n",
        "import gradio as gr\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "PPLX_API_KEY = os.environ.get(\"PERPLEXITY_API_KEY\", \"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\")\n",
        "PPLX_BASE_URL = \"https://api.perplexity.ai\"\n",
        "MODEL_NAME = \"sonar-pro\"\n",
        "TIMEOUT = 40\n",
        "\n",
        "\n",
        "# =========================\n",
        "# SYSTEM PROMPT (RU ONLY)\n",
        "# =========================\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "–¢—ã ‚Äî AI-—Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞–º:\n",
        "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ, –≥–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ, NLP, LLM –∏ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏.\n",
        "\n",
        "–¢—ã –æ—Ç–≤–µ—á–∞–µ—à—å –°–¢–†–û–ì–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.\n",
        "\n",
        "–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –û–ë–Ø–ó–ê–¢–ï–õ–ï–ù:\n",
        "\n",
        "1) –ö—Ä–∞—Ç–∫–æ\n",
        "2) –ü–æ—è—Å–Ω–µ–Ω–∏–µ\n",
        "3) –ü—Ä–∏–º–µ—Ä (–∫–æ–¥ –∏–ª–∏ –ø—Å–µ–≤–¥–æ–∫–æ–¥)\n",
        "4) –ò—Å—Ç–æ—á–Ω–∏–∫–∏ (Markdown-—Å—Å—ã–ª–∫–∏)\n",
        "---\n",
        "5) –°–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∞ (3‚Äì5 –≤–æ–ø—Ä–æ—Å–æ–≤)\n",
        "6) –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ç–µ–º—ã (–º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫)\n",
        "\n",
        "–ü—Ä–∞–≤–∏–ª–∞:\n",
        "- –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏.\n",
        "- –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –Ω–∞–ø–∏—à–∏ –æ–± —ç—Ç–æ–º —è–≤–Ω–æ.\n",
        "- –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–π NeurIPS, ICML, ICLR, ACL, CVPR, arXiv.\n",
        "- –í –±–ª–æ–∫–µ ¬´–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ç–µ–º—ã¬ª –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ñ–æ—Ä–º–∞—Ç:\n",
        "  - –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# =========================\n",
        "# FALLBACK TOPICS (RU)\n",
        "# =========================\n",
        "TOPIC_HIERARCHY = {\n",
        "    \"Machine Learning\": {\n",
        "        \"Beginner\": [\n",
        "            \"–ß—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\",\n",
        "            \"–û–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª–µ–º –∏ –±–µ–∑ —É—á–∏—Ç–µ–ª—è\",\n",
        "            \"–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è\",\n",
        "            \"–§—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å\",\n",
        "            \"–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫\",\n",
        "            \"–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π\",\n",
        "        ],\n",
        "        \"Intermediate\": [\n",
        "            \"–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥\",\n",
        "            \"Bias-Variance Tradeoff\",\n",
        "            \"–ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è\",\n",
        "            \"–ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\",\n",
        "            \"–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π (SHAP)\",\n",
        "        ],\n",
        "        \"Advanced\": [\n",
        "            \"–ü—Ä–∏—á–∏–Ω–Ω–æ-—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–π –≤—ã–≤–æ–¥\",\n",
        "            \"–°–¥–≤–∏–≥ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π\",\n",
        "            \"–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ ML-–º–æ–¥–µ–ª–µ–π\",\n",
        "            \"–≠—Ç–∏–∫–∞ –∏ fairness –≤ ML\",\n",
        "        ],\n",
        "    },\n",
        "\n",
        "    \"Large Language Models\": {\n",
        "        \"Beginner\": [\n",
        "            \"–ß—Ç–æ —Ç–∞–∫–æ–µ Transformer\",\n",
        "            \"Self-attention –º–µ—Ö–∞–Ω–∏–∑–º\",\n",
        "            \"–¢–æ–∫–µ–Ω—ã –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç\",\n",
        "            \"Prompt engineering\",\n",
        "            \"–ü–æ—á–µ–º—É LLM –≥–∞–ª–ª—é—Ü–∏–Ω–∏—Ä—É—é—Ç\",\n",
        "        ],\n",
        "        \"Intermediate\": [\n",
        "            \"–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Transformer\",\n",
        "            \"Instruction tuning\",\n",
        "            \"RAG (Retrieval-Augmented Generation)\",\n",
        "            \"–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ LLM\",\n",
        "            \"Prompt injection\",\n",
        "        ],\n",
        "        \"Advanced\": [\n",
        "            \"RLHF –∏ DPO\",\n",
        "            \"–ê–≥–µ–Ω—Ç–Ω—ã–µ LLM-—Å–∏—Å—Ç–µ–º—ã\",\n",
        "            \"–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å LLM\",\n",
        "            \"–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–Ω–∞–Ω–∏–π –º–æ–¥–µ–ª–µ–π\",\n",
        "        ],\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "# =========================\n",
        "# HELPERS\n",
        "# =========================\n",
        "def default_question(area, level):\n",
        "    if area == \"Machine Learning\" and level == \"Beginner\":\n",
        "        return \"–ß—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ? –û–±—ä—è—Å–Ω–∏ –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏.\"\n",
        "    if area == \"Large Language Models\":\n",
        "        return \"–û–±—ä—è—Å–Ω–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É Transformer –∏ –º–µ—Ö–∞–Ω–∏–∑–º attention.\"\n",
        "    return f\"–û–±—ä—è—Å–Ω–∏ –∫–ª—é—á–µ–≤—É—é —Ç–µ–º—É —É—Ä–æ–≤–Ω—è {level} –≤ –æ–±–ª–∞—Å—Ç–∏ {area}.\"\n",
        "\n",
        "\n",
        "def extract_next_topics(text):\n",
        "    if not text:\n",
        "        return []\n",
        "\n",
        "    match = re.search(r\"–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ç–µ–º—ã\\s*[:Ôºö]?\\n\", text, re.IGNORECASE)\n",
        "    if not match:\n",
        "        return []\n",
        "\n",
        "    block = text[match.end():]\n",
        "    topics = []\n",
        "\n",
        "    for line in block.split(\"\\n\"):\n",
        "        m = re.match(r\"^[-‚Ä¢*]\\s+(.*)\", line.strip())\n",
        "        if m:\n",
        "            topics.append(m.group(1).strip())\n",
        "\n",
        "    return list(dict.fromkeys(topics))[:8]\n",
        "\n",
        "\n",
        "def fallback_topics(area, level):\n",
        "    return TOPIC_HIERARCHY.get(area, {}).get(level, [])\n",
        "\n",
        "\n",
        "# =========================\n",
        "# PERPLEXITY API\n",
        "# =========================\n",
        "def pplx_search(query):\n",
        "    url = f\"{PPLX_BASE_URL}/search\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {PPLX_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "    }\n",
        "    payload = {\"query\": query, \"max_results\": 5}\n",
        "\n",
        "    try:\n",
        "        r = requests.post(url, headers=headers, json=payload, timeout=TIMEOUT)\n",
        "        return r.json().get(\"results\", [])\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "\n",
        "def pplx_chat(question, area, level, sources):\n",
        "    url = f\"{PPLX_BASE_URL}/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {PPLX_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "    }\n",
        "\n",
        "    user_content = f\"\"\"\n",
        "–û–ë–õ–ê–°–¢–¨: {area}\n",
        "–£–†–û–í–ï–ù–¨: {level}\n",
        "\n",
        "–í–û–ü–†–û–°:\n",
        "{question}\n",
        "\n",
        "–ò–°–¢–û–ß–ù–ò–ö–ò:\n",
        "{sources}\n",
        "\"\"\"\n",
        "\n",
        "    payload = {\n",
        "        \"model\": MODEL_NAME,\n",
        "        \"temperature\": 0.2,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": user_content},\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    r = requests.post(url, headers=headers, json=payload, timeout=TIMEOUT)\n",
        "    return r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "\n",
        "# =========================\n",
        "# BACKEND LOGIC\n",
        "# =========================\n",
        "def handle_question(area, level, question):\n",
        "    if not question.strip():\n",
        "        question = default_question(area, level)\n",
        "\n",
        "    sources = pplx_search(question)\n",
        "    sources_text = \"\\n\".join(\n",
        "        [f\"- {s.get('title','')} ({s.get('url','')})\" for s in sources]\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        answer = pplx_chat(question, area, level, sources_text)\n",
        "    except:\n",
        "        answer = \"‚ùå –û—à–∏–±–∫–∞ API. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.\"\n",
        "\n",
        "    next_topics = extract_next_topics(answer)\n",
        "    if not next_topics:\n",
        "        next_topics = fallback_topics(area, level)\n",
        "\n",
        "    return answer, gr.Dropdown(choices=next_topics)\n",
        "\n",
        "\n",
        "def handle_followup(area, level, topic):\n",
        "    return handle_question(area, level, topic)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# GRADIO UI (COLAB)\n",
        "# =========================\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üéì AI-–†–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ ML / DL / NLP / LLM / Diffusion\")\n",
        "\n",
        "    with gr.Row():\n",
        "        area = gr.Dropdown(\n",
        "            [\"Machine Learning\", \"Deep Learning\", \"NLP\", \"Large Language Models\", \"Diffusion Models\"],\n",
        "            label=\"–û–±–ª–∞—Å—Ç—å\"\n",
        "        )\n",
        "        level = gr.Radio(\n",
        "            [\"Beginner\", \"Intermediate\", \"Advanced\"],\n",
        "            label=\"–£—Ä–æ–≤–µ–Ω—å\"\n",
        "        )\n",
        "\n",
        "    question = gr.Textbox(\n",
        "        label=\"–í–∞—à –≤–æ–ø—Ä–æ—Å –∏–ª–∏ —Ç–µ–º–∞\",\n",
        "        placeholder=\"–ù–∞–ø—Ä–∏–º–µ—Ä: –û–±—ä—è—Å–Ω–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É Transformer\"\n",
        "    )\n",
        "\n",
        "    ask_btn = gr.Button(\"–ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å\")\n",
        "    answer_md = gr.Markdown()\n",
        "\n",
        "    next_topics = gr.Dropdown(label=\"üìå  –û—Ç–≤–µ—Ç—ã \", interactive=True)\n",
        "    continue_btn = gr.Button(\"–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ\")\n",
        "\n",
        "    ask_btn.click(\n",
        "        handle_question,\n",
        "        inputs=[area, level, question],\n",
        "        outputs=[answer_md, next_topics],\n",
        "    )\n",
        "\n",
        "    continue_btn.click(\n",
        "        handle_followup,\n",
        "        inputs=[area, level, next_topics],\n",
        "        outputs=[answer_md, next_topics],\n",
        "    )\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "QFgbJBIhpDoe",
        "outputId": "a57fb8b6-ef0b-44d5-8b2e-87005940ac02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://bb3f8e2f977c756719.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://bb3f8e2f977c756719.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}